<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		 
			
  
    <meta name="twitter:card" content="summary"/>
    
      <meta name="twitter:image" content="https://ealebed.github.io/images/avatar.png" />
    
  
  
  <meta name="twitter:title" content="Установка и настройка GlusterFS-server 3.5.2 в ОС Debian"/>
  <meta name="twitter:description" content="GlusterFS — простая в настройке и использовании распределенная файловая система, работающая поверх основной файловой системы. Давайте разберемся с установкой и GlusterFS-server в ОС Debian Wheezy!

"/>
  
    <meta name="twitter:site" content="@ealebed"/>
  
  
  
  
    <meta name="twitter:creator" content="@Yevhen Lebid"/>
  



		
		<meta name="author" content="Yevhen Lebid">
		<meta name="description" content="Yevhen Lebid&#39;s website">
		<meta name="generator" content="Hugo 0.32.2" />
		<title>Установка и настройка GlusterFS-server 3.5.2 в ОС Debian &middot; Yevhen Lebid&#39;s website</title>
		<link rel="shortcut icon" href="https://ealebed.github.io/images/favicon.ico">
		<link rel="stylesheet" href="https://ealebed.github.io/css/style.css">
		<link rel="stylesheet" href="https://ealebed.github.io/css/highlight.css">

		<link rel="stylesheet" href="https://ealebed.github.io/css/font-awesome.min.css">

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='https://ealebed.github.io/'> <span class="arrow">←</span>Home</a>
	
	<a href='https://ealebed.github.io/posts'>Archive</a>
	<a href='https://ealebed.github.io/tags'>Tags</a>
	<a href='https://ealebed.github.io/about'>About</a>

	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        Установка и настройка GlusterFS-server 3.5.2 в ОС Debian
                    </h1>
                    <h2 class="headline">
                    Oct 24, 2016 22:41
                    · 684 words
                    · 4 minute read
                      <span class="tags">
                      
                      
                          
                              <a href="https://ealebed.github.io/tags/glusterfs">glusterfs</a>
                          
                      
                      
                      </span>
                    </h2>
                </header>
                <section id="post-body">
                    <p><strong>GlusterFS</strong> — простая в настройке и использовании распределенная файловая система, работающая поверх основной файловой системы. Давайте разберемся с <strong>установкой и GlusterFS-server в ОС Debian Wheezy</strong>!</p>

<p></p>

<p>Прежде всего, хочу объяснить, почему был выбран <strong>GlusterFS-server</strong> версии 3.5.2 — далеко не самой свежей на момент написания статьи. В моем случае, на нескольких серверах под управлением ОС Debian Wheezy уже был настроен и успешно использовался <strong>GlusterFS-server</strong> версии 3.2.7, но при необходимости добавления новых узлов в кластер возникли сложности. Как выяснилось, для расширения кластера нужен <strong>GlusterFS-server</strong> версии не ниже 3.3, а в репозитории wheezy-backports как раз нашлась версия 3.5.2.</p>

<p>Считаем, что все хосты будущего кластера доступны друг для друга, в firewall открыты TCP порты 111, 24007-24050 и созданы все необходимы каталоги/точки монтирования.</p>

<p><strong>Примечание.</strong> В нашем примере GlusterFS настраивается как <code>replicated volume</code> на 5 машинах с локальными ip-адресами 192.168.0.1, 192.168.0.3, 192.168.0.7, 192.168.0.13 и 192.168.0.14</p>

<p><strong>Устанавливаем GlusterFS-server</strong> на всех серверах:</p>

<pre><code class="language-bash">aptitude install -t wheezy-backports glusterfs-server
</code></pre>

<p>Сразу после установки проверим состояние кластера:</p>

<pre><code class="language-bash">gluster peer status
Number of Peers: 0
</code></pre>

<p>Подключаемся на любой хост из нашего списка (например, 192.168.0.1) и создаем кластер:</p>

<pre><code class="language-bash">gluster peer probe 192.168.0.3
peer probe: success.
</code></pre>

<pre><code class="language-bash">gluster peer probe 192.168.0.7
peer probe: failed: 192.168.0.7 is already part of another cluster
</code></pre>

<pre><code class="language-bash">gluster peer probe 192.168.0.13
peer probe: success.
</code></pre>

<pre><code class="language-bash">gluster peer probe 192.168.0.14
peer probe: success.
</code></pre>

<p>Добавлять в список хостов кластера «самого себя» не нужно:</p>

<pre><code class="language-bash">gluster peer probe 192.168.0.1
peer probe: success. Probe on localhost not needed
</code></pre>

<p>Если вы ошибетесь и попробуете добавить один и тот же сервер дважды, то увидите примерно следующее:</p>

<pre><code class="language-bash">gluster peer probe 192.168.0.3
peer probe: success. Host 192.168.0.3 port 24007 already in peer list
</code></pre>

<p>Как вы наверняка заметили, что-то пошло не так при добавлении узла с ip-адресом 192.168.0.7. Проверяем состояние нашего кластера:</p>

<pre><code class="language-bash">gluster peer status
Number of Peers: 4

Hostname: 192.168.0.7
Uuid: 1b138a89-64dc-4a5e-8095-8892abaaf0e5
State: Accepted peer request (Connected)

Hostname: 192.168.0.3
Uuid: b9789ef4-1f26-4320-a7ba-0902c3434d76
State: Peer in Cluster (Connected)

Hostname: 192.168.0.13
Uuid: c8618f71-fdb3-4f28-8266-9eebca69e4e2
State: Peer in Cluster (Connected)

Hostname: 192.168.0.14
Uuid: 92876551-847a-4a9d-9a86-07c23b3e91f0
State: Peer in Cluster (Connected)
</code></pre>

<p>Мы не можем создать кластер, так как один из его узлов находится в состоянии <code>Accepted peer request</code>. В моем случае всему виной старые конфиги <strong>GlusterFS-server</strong> 3.2.7, поэтому делаем так:</p>

<pre><code class="language-bash">gluster peer detach 192.168.0.7
peer detach: success
</code></pre>

<pre><code class="language-bash">gluster peer probe 192.168.0.7
peer probe: success.
</code></pre>

<p>Теперь состояние узлов соответствует нашим ожиданиям:</p>

<pre><code class="language-bash">gluster peer status
Number of Peers: 4

Hostname: 192.168.0.13
Uuid: c8618f71-fdb3-4f28-8266-9eebca69e4e2
State: Peer in Cluster (Connected)

Hostname: 192.168.0.3
Uuid: b9789ef4-1f26-4320-a7ba-0902c3434d76
State: Peer in Cluster (Connected)

Hostname: 192.168.0.14
Uuid: 92876551-847a-4a9d-9a86-07c23b3e91f0
State: Peer in Cluster (Connected)

Hostname: 192.168.0.7
Uuid: 5837f180-6b00-403c-83ff-e993ef7bf4ef
State: Peer in Cluster (Connected)
</code></pre>

<p>Можно сделать аналогичные проверки со всех хостов кластера. Теперь создадим реплицируемый том (<code>volume</code>):</p>

<pre><code class="language-bash">gluster volume create www replica 5 transport tcp 192.168.0.1:/var/www/testsite 192.168.0.7:/var/www/testsite 192.168.0.3:/var/www/testsite 192.168.0.13:/var/www/testsite 192.168.0.14:/var/www/testsite
volume create: www: success: please start the volume to access data
</code></pre>

<p>Запускаем созданный том:</p>

<pre><code class="language-bash">gluster volume start www
volume start: www: success
</code></pre>

<p>После чего проверим статус нашего тома:</p>

<pre><code class="language-bash">gluster volume status
Status of volume: www
Gluster process						Port	Online	Pid
------------------------------------------------------------------------------
Brick 192.168.0.1:/var/www/testsite			49152	Y	29660
Brick 192.168.0.7:/var/www/testsite			49152	Y	13559
Brick 192.168.0.3:/var/www/testsite			49153	Y	7743
Brick 192.168.0.13:/var/www/testsite			49152	Y	28423
Brick 192.168.0.14:/var/www/testsite			49152	Y	21147
NFS Server on localhost					2049	Y	29674
Self-heal Daemon on localhost				N/A	Y	29679
NFS Server on 192.168.0.14				2049	Y	21161
Self-heal Daemon on 192.168.0.14			N/A	Y	21167
NFS Server on 192.168.0.13				2049	Y	28437
Self-heal Daemon on 192.168.0.13			N/A	Y	28442
NFS Server on 192.168.0.3				2049	Y	7761
Self-heal Daemon on 192.168.0.3				N/A	Y	7766
NFS Server on 192.168.0.7				2049	Y	13631
Self-heal Daemon on 192.168.0.7				N/A	Y	13642

Task Status of Volume www
------------------------------------------------------------------------------
There are no active volume tasks
</code></pre>

<p>Интересующую информацию о реплицируемом томе можно еще посмотреть так:</p>

<pre><code class="language-bash">gluster volume info

Volume Name: www
Type: Replicate
Volume ID: 782e8fd8-0a72-4966-9590-77c244bce3b6
Status: Started
Number of Bricks: 1 x 5 = 5
Transport-type: tcp
Bricks:
Brick1: 192.168.0.1:/var/www/testsite
Brick2: 192.168.0.7:/var/www/testsite
Brick3: 192.168.0.3:/var/www/testsite
Brick4: 192.168.0.13:/var/www/testsite
Brick5: 192.168.0.14:/var/www/testsite
</code></pre>

<p>Добавляем в <code>/etc/fstab</code> на первом узле (192.168.0.1) следующую строку:</p>

<pre><code class="language-text">...
localhost:/www    /var/www/svnup             glusterfs rw,nosuid,nodev,exec,nouser,async,_netdev  0 0
...
</code></pre>

<p>Монтируем:</p>

<pre><code class="language-bash">mount /var/www/svnup
</code></pre>

<p>Теперь можно &lsquo;заливать&rsquo; данные в каталог <code>/var/www/svnup</code> на первом узле кластера и они будут легко и просто реплицироваться на все 5 хостов к каталог <code>/var/www/testsite</code>. Это очень удобно, например, для распределения web-контента на бэкэндах.</p>
                </section>
            </article>

            
                <a class="twitter" href="https://twitter.com/intent/tweet?text=https%3a%2f%2fealebed.github.io%2fposts%2f2016%2f%25D1%2583%25D1%2581%25D1%2582%25D0%25B0%25D0%25BD%25D0%25BE%25D0%25B2%25D0%25BA%25D0%25B0-%25D0%25B8-%25D0%25BD%25D0%25B0%25D1%2581%25D1%2582%25D1%2580%25D0%25BE%25D0%25B9%25D0%25BA%25D0%25B0-glusterfs-server-3.5.2-%25D0%25B2-%25D0%25BE%25D1%2581-debian%2f - %d0%a3%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0%20%d0%b8%20%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b0%20GlusterFS-server%203.5.2%20%d0%b2%20%d0%9e%d0%a1%20Debian by @ealebed"><span class="icon-twitter"> tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

            

            
                <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'ealebed'; 

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

            

            
                <ul id="post-list" class="archive readmore">
    <h3>Read more</h3>

    
    
    
        <li>
            <a href="/posts/2019/%D1%80%D0%B5%D1%81%D1%83%D1%80%D1%81%D1%8B-%D0%B2-kubernetes-%D1%87%D0%B0%D1%81%D1%82%D1%8C-2-cpu/">Ресурсы в Kubernetes. Часть 2: Процессор (CPU)<aside class="dates">Jul 25 2019</aside></a>
        </li>
    
        <li>
            <a href="/posts/2019/%D1%80%D0%B5%D1%81%D1%83%D1%80%D1%81%D1%8B-%D0%B2-kubernetes-%D1%87%D0%B0%D1%81%D1%82%D1%8C-1-memory/">Ресурсы в Kubernetes. Часть 1: Память (Memory)<aside class="dates">Jul 15 2019</aside></a>
        </li>
    
        <li>
            <a href="/posts/2019/%D0%B7%D0%BD%D0%B0%D0%BA%D0%BE%D0%BC%D1%81%D1%82%D0%B2%D0%BE-%D1%81-kubernetes-%D1%87%D0%B0%D1%81%D1%82%D1%8C-19-horizontalpodautoscaler/">Знакомство с Kubernetes. Часть 19: HorizontalPodAutoscaler<aside class="dates">Jun 12 2019</aside></a>
        </li>
    
        <li>
            <a href="/posts/2019/deploy-to-k8s-with-spinnaker-%D1%87%D0%B0%D1%81%D1%82%D1%8C-1-%D1%83%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BA%D0%B0/">Deploy to k8s with Spinnaker. Часть 1: Установка<aside class="dates">Jan 24 2019</aside></a>
        </li>
    
        <li>
            <a href="/posts/2019/gradle-checkstyle-plugin/">Gradle Checkstyle plugin<aside class="dates">Jan 8 2019</aside></a>
        </li>
    
</ul>

            

            <footer id="footer">
    
        <div id="social">
	
	
    <a class="symbol" href="https://www.facebook.com/ealebed">
        <i class="fa fa-facebook-square"></i>
    </a>
    
    <a class="symbol" href="https://www.github.com/ealebed">
        <i class="fa fa-github-square"></i>
    </a>
    
    <a class="symbol" href="https://www.twitter.com/ealebed">
        <i class="fa fa-twitter-square"></i>
    </a>
    

</div>

    
    <p class="small">
    
       © Copyright 2019 <i class="fa fa-heart" aria-hidden="true"></i> Yevhen Lebid
    
    </p>
</footer>

        </section>

        <script src="https://ealebed.github.io/js/jquery-2.2.4.min.js"></script>
<script src="https://ealebed.github.io/js/main.js"></script>
<script src="https://ealebed.github.io/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




  
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-112453311-1', 'auto');
ga('send', 'pageview');
</script>



    </body>
</html>
